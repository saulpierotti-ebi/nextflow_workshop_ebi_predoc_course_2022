[["index.html", "Nextflow workshop - EBI predoc course 2022 Introduction to the workshop", " Nextflow workshop - EBI predoc course 2022 Saul Pierotti, PhD student in the Birney group (European Bioinformatics Institute) September 29, 2022 Introduction to the workshop This workshop aims at introducing you to the world of workflow managers, in particular the workflow manager Nextflow. This workshop was written as a practical for the EMBL-EBI predoc course, 2022 cohort. I hope that you will find it useful, and in any case I would be happy to hear your feedback on it. You can contact me at saul@ebi.ac.uk. The workshop is written with an increasing level of difficulty, so feel free to skip what is too easy for you or stop when things become too complex. Finally, I wanted to point out that in this workshop I am using the words “pipeline” and “workflow” interchangeably, so consider them as equivalent. "],["introduction.html", "1 Introduction 1.1 Prerequisites 1.2 What is Nextflow? 1.3 Learning objectives 1.4 Setup 1.5 Getting started", " 1 Introduction 1.1 Prerequisites Familiarity with the Linux shell, as well as basic programming constructs such as for/while loops and if/else statements is assumed. Familiarity with at least one scripting language such as R or Python will be beneficial. A basic knowledge of virtual environments and software containers would be helpful. Basic knowledge of git is required. 1.2 What is Nextflow? Nextflow is an open-source workflow manager consisting of a domain specific language built as a superset of the Groovy programming language, which is itself a superset of Java. The purpose of Nextflow is to make it easier to coordinate the execution of complex data analysis pipelines, and to facilitate the execution of such pipelines in cloud environments and high-performance clusters. In practice, Nextflow allows you to declare how the output of some processes in a pipeline are fed as the input of other processes, leading to the production of a final result. In addition, Nextflow allows the specification of software requirements for each process using conda environments, docker containers, and a variety of other solutions. Once a pipeline has been written in Nextflow, it can be easily scaled from a local laptop to a high-performance cluster or cloud environment without any modification, with Nextflow taking care of environment-specific commands (for example, submitting appropriate jobs to a batch scheduler). Moreover, the pipeline execution is parallelised if the dependencies among different processes allow it. A motivation for using a workflow manager such as Nextflow is also to increase the reproducibility of your data analysis. Finally, each processes in Nextflow is executed in its own unique directory, with automatic staging of the required inputs, so there is no need to think about filename collisions and file locations when developing your pipeline. Nextflow is developed and maintained by Seqera Labs. The project was started in Cedric Notredame’s lab at the Centre for Genomic Regulation (CRG) in Barcelona, Spain. Nextflow was conceived with bioinformatics as its key use-case, but it is domain-agnostic and can be used for any data-intensive workflow. 1.3 Learning objectives After following this tutorial, the learner will be autonomous in using nextflow for their own data analysis. They will understand fundamental Nextflow concepts such as processes, workflows, channels, they will be able to write a configuration file to alter the resources allocated for a processes and the software environment of execution, and they will be able to deploy a community-curated pipeline from nf-core. 1.4 Setup Install mamba, a faster alternative to conda curl -L -O &quot;https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-$(uname)-$(uname -m).sh&quot; bash Mambaforge-$(uname)-$(uname -m).sh Setup the shell to use mamba mamba init Close and re-open your shell. Then, create a mamba environment for installing Nextflow mamba create -n nextflow nextflow Now activate the environment that you just created mamba activate nextflow Create an empty git repository in your GitHub account and clone it locally. I will pretend that this repository is called my_repo in this workshop. Don’t forget to replace this with the name of your actual repository. cd my_repo You can use a text editor of your choice to write Nextflow code. For example, you may want to use Atom. I recommend to add Nextflow language support to Atom by clicking here. Create some essential files that we will be working on inside your new repository touch main.nf touch nextflow.config 1.5 Getting started 1.5.1 General anatomy of a Nextflow workflow A Nextflow workflow is usually represented by a git repository containing all the files describing the workflow logic, configurations, and dependencies. Text files containing Nextflow code usually have the .nf extension (i.e. my_file.nf). It does not really matter how you name your files, as long as they contain valid Nextflow code, but for consistency the best practice is to call the file describing the workflow as main.nf and place it at the root of your repository. The main.nf file can access code from other Nextflow scripts, called sub-workflows, that can have arbitrary names. The best practice is to place such additional Nextflow scripts under the folder workflows in the root of the repository. So for example an additional Nextflow script could be named workflows/preprocessing.nf. We will explore later the usage of sub-workflows, so don’t worry if you don’t understand their purpose yet. The configurations for the pipeline need to be placed in a file called nextflow.config at the root of the repository. Note that differently from what was said before regarding main.nf, this name is mandatory for Nextflow to properly recognise the file. The nextflow.config file can contain for example resource requirements, execution, parameters, and metadata about your workflow. We will explore more in depth the usage of configurations files in a later section. Scripts (in any language, for example R or Python) that are used in the execution of specific processes in your pipeline should be placed in the folder bin. Scripts placed here are automatically recognise by Nextflow during task execution without the need to specify their full path. Additional files needed for your workflow, for example a table containing some metadata for your samples, are usually placed under the folder assets. However this is not required and many workflows do not have an assets folder. Inputs to the workflow are usually defined in a so-called “sample sheet” that should contain the (preferably) absolute file path to the input files end eventual sample-specific parameters for task execution. Best practice is to have your sample sheet formatted as a csv file with an appropriate header. Note that the sample sheet is not part of the pipeline itself. The absolute path to the sample sheet is usually provided to Nextflow either as a command-line parameter or in the nextflow.config file. In order to execute your workflow, you would run (do not do it now, we still need to write the workflow) nextflow run main.nf at the root of your repository if your workflow is in a file named main.nf. This would prompt Nextflow to read the main.nf file and eventual sub-workflows, extract the workflow logic from it, load the configurations in nextflow.config, and coordinate the execution of the different steps in your pipeline to produce the final result. 1.5.2 Nextflow domain specific language versions Before starting, it is important to know that Nextflow as it was initially developed is referred to as Domain Specific Language 1 (DSL1). A major change in the Nextflow syntax was done by its developers, and the new syntax is referred to as DSL 2. In this workshop we will be using exclusively the new DSL2 syntax. For this reason, you need to add the following line at the top of your main.nf file: nextflow.enable.dsl = 2 So if in the future you will find yourself looking at a Nextflow workflow which is written very differently from what you are used to, it will probably be written according to DSL1 instead of DSL2. 1.5.3 Core concepts A Nextflow workflow is defined by a set of processes, which execute a single task each, which are coordinate by one or more workflows. So for example there may be a processes called align_fastq that takes in input a fastq file and a reference genome and uses the software bwa-mem2 to align it, producing an aligned cram file in output. A processes defines as a minimum some output and the command to be executed. Inputs are usually also defined but there may be processes that do not need any input and instead perform a static computation. Many additional parameters can be specified for a process, for example the software needed, or how much memory or time is required for its execution. We will explore processes and their definition more in detail in a later section. If processes determine what is to be executed and how, workflows instead determine the logic of execution and how different processes communicate with each other. So for example there may be a workflow called SNP_CALLING that takes a fastq file in input, uses the process align_fastq to obtain an aligned cram file, then gives that cram file in input to another process called gatk_call that uses it to create a vcf file containing genetic variants. Processes communicate with each other using so-called “channels”, which are unidirectional First-In-First-Out (FIFO) queues. This means that a channel is populated with a set of elements (for example, files) produced by a process in the order in which they are produced. Then, these elements are consumed one by one by another process in the same order. Several ways to manipulate, merge, and split channel exist, and we will explore them later. So for example the workflow that I described above may define an input channel containing the fastq files in input, and a channel connecting the output of align_fastq to the input of gatk_call. Note that channels are unidirectional: communication happens only in one direction, from outputs to inputs. 1.5.4 Your first workflow Now that you know the basics of what a Nextflow workflow is, we will write a simple workflow and we will execute it. First of all, open the file main.nf that you created before at the root of your repository in a text editor and add the following to it // this is a comment process say_hello { // comments can be written anywhere output: &quot;hello_world.txt&quot; script: &quot;&quot;&quot; echo &quot;This is the EBI predoc course&quot; &gt; hello_world.txt &quot;&quot;&quot; } workflow { say_hello() say_hello.out.view() } If you want to see how your main.nf should look like at this stage open this hidden section Code nextflow.enable.dsl = 2 // this is a comment process say_hello { // comments can be written anywhere output: path &quot;hello_world.txt&quot; script: &quot;&quot;&quot; echo &quot;This is the EBI predoc course&quot; &gt; hello_world.txt &quot;&quot;&quot; } workflow { say_hello() say_hello.out.view() } Now open the file nextflow.config and add the following line // you can also put comments in nextflow.config workDir = &quot;~/nextflow_workdir&quot; Now run the workflow executing from the root of your repository the following nextflow run main.nf You should see a bunch of information about your workflow and finally you will see the name of the file we just created, hello_world.txt, appear on your terminal. Let’s now examine the code step by step: In nextflow.config we declared our working directory to be ~/nextflow_workdir with the keyword workDir. The working directory is where Nextflow actually stores your files during intermediate processing. Lines starting with // define a comment in groovy, and they are ignored. The keyword process defines a process, with the statement that follows defining the process name. So process say_hello creates a process named say_hello. Curly braces enclose a block of code, so process say_hello {&lt;some code&gt;} is understood by Nextflow as defining &lt;some code&gt; to belong to the process named say_hello. The keyword output: when used inside of a process defines the expected outputs that that process should produce. If the declared output is absent at the end of the process’ execution the execution fails. Several types of outputs can be defined, and path is one of them. The keyword path defines what comes after it to be a file. Output files are named in the output block after the path qualifier. They should be placed inside a string. Strings are enclosed in quotes in groovy (\"this is a string\"). The script: keyword defines the actual command to be executed in the process. The command should be provided as a string. Since commands can be long, here a multi-line string is used. In groovy, multi-line strings are enclosed in there quotes What is declared in the script: block is executed in the shell by default, so we should write bash code there The command that we wrote, echo \"This is the EBI predoc course\" &gt; hello_world.txt, creates a file called hello_world.txt containing the string \"This is the EBI predoc course\" &quot;&quot;&quot; this is a multi-line string it is very long &quot;&quot;&quot; The keyword workflow defines a workflow, that we left unnamed in this case. The last workflow to be written in your main.nf file is automatically executed by Nextflow. The workflow that we defined executes the process say_hello that we defined above with the command say_hello(), as if it was a function. The output of the process say_hello is captured by say_hello.out, which is a channel. In this case it will contain just the file hello_world.txt The operator view() just echoes to the terminal the content of the channel. In this case it prints hello_world.txt to our shell. So to put everything together, when you ran nextflow run main.nf Nextflow read the main.nf file, it found the last workflow, which we left unnamed, and executed it. Some additional notes: It is possible to write path(\"a_file.txt\") or path a_file.txt, they are equivalent statements There is no need to think about where we are creating our files, Nextflow under the hood creates a private directory for each execution and takes care of moving files around as needed by other processes It is common practice to chain different operators on a channel. For this reason, it is possible to also write them on separate lines. So the following is equivalent to say_hello.out.view(). Note that spaces and tab charachters are just for visual clarity and are not required say_hello.out .view() Explore the working directory ~/nextflow_workdir. It contains a directory with a strange alphanumeric name like 00/fjdanurew9gihwepw1455idusodhfweioru (NOTE: yours will have a different name). One different directory like this is created by Nextflow for the execution of each task (a task is an instance of a process, a process is the definition itself, while a task is created each time that process is executed on different inputs). Inside the directory with the strange name, you will see the file that we just created, hello_world.txt Read the content of the file with cat hello_world.txt. You should see This is the EBI predoc course in your terminal. "],["a-basic-workflow.html", "2 A basic workflow", " 2 A basic workflow Let’s now step up a bit the complexity and write a workflow containing two processes that communicate with each other. Add the following process to your main.nf file. process duplicate_lines { input: path my_file output: &quot;${my_file.simpleName}.duplicated.txt&quot; script: &quot;&quot;&quot; cat $my_file $my_file &gt; ${my_file.simpleName}.duplicated.txt &quot;&quot;&quot; } And modify your workflow block as follows workflow { say_hello() duplicate_lines( say_hello.out ) duplicate_lines.out.view() } If you want to see how your main.nf should look like at this stage open this hidden section Code nextflow.enable.dsl = 2 // this is a comment process say_hello { // comments can be written anywhere output: path &quot;hello_world.txt&quot; script: &quot;&quot;&quot; echo &quot;This is the EBI predoc course&quot; &gt; hello_world.txt &quot;&quot;&quot; } process duplicate_lines { input: path my_file output: &quot;${my_file.simpleName}.duplicated.txt&quot; script: &quot;&quot;&quot; cat $my_file $my_file &gt; ${my_file.simpleName}.duplicated.txt &quot;&quot;&quot; } workflow { say_hello() duplicate_lines( say_hello.out ) duplicate_lines.out.view() } Now run again the workflow with nextflow run main.nf. This time your workflow should print the name of a file called hello_world.duplicated.txt. Copy the full path to that file and check its content. Be sure to substitute &lt;your_directory_name&gt; with the path that you see on the Nextflow output. cat &lt;your_directory_name&gt;/hello_world.duplicated.txt This should print the following to the terminal This is the EBI predoc course This is the EBI predoc course So as you see, the content of the hello_world.txt file that we created before has been duplicated and now appears on two lines. So let’s analyse what happened this time: We created another process called duplicate_lines which duplicates a given file thanks to its script command cat $my_file $my_file &gt; ${my_file.simpleName}.duplicated.txt duplicate_lines declares an input: block. The input block is similar to the output block that we saw before in that it can use the path qualifier to declare the input to be a file. However, what comes after path does not need to be a real filename, it is just a variable name (note that it is not quoted). Nextflow replace that variable with the real name of the file given in input. In the script and output blocks we can refer to the inputs by specifying $my_file. Note that we need to use the same name used in the input declaration. It is possible to enclose the variable name in curly braces to demark it from other text. So ${my_file} is equivalent to $my_file. We applied the operator simpleName to the variable $my_file by writing ${my_file.simpleName}. This removes the path and the extension from my_file, so that we can use it to name our output file (if $my_file contains the value \"/some/path/hello_world.txt\", then ${my_file.simpleName} contains only hello_world). In the workflow block we called the process duplicate_lines with say_hello.out as an argument. So the output of say_hello is used as an input for duplicate_lines. Note that the number of arguments provided to a process must match the number of arguments declared in its input block. "],["additional-resources.html", "3 Additional resources", " 3 Additional resources Nextflow documentation: https://www.nextflow.io/docs/latest/index.html Nextflow workshop from the Nextflow authors: https://www.nextflow.io/blog/2022/learn-nextflow-in-2022.html YouTube playlist: https://www.youtube.com/playlist?list=PLPZ8WHdZGxmUv4W8ZRlmstkZwhb_fencI Post on Medium on Nextflow from 23andMe: https://medium.com/23andme-engineering/introduction-to-nextflow-4d0e3b6768d1 Nextflow course on SofwareCarpentries: https://carpentries-incubator.github.io/workflows-nextflow/index.html "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
