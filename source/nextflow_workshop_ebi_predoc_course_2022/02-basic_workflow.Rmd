# A basic workflow

Let's now step up a bit the complexity and write a workflow containing two processes that communicate with each other.
Add the following process to your `main.nf` file.

## Multiple processes and publication of workflow outputs

```groovy
process duplicate_lines {
    publishDir "../nextflow_output/duplicate_lines"

    input:
        path my_file
    output:
        path "${my_file.simpleName}.duplicated.txt"
    script:
        """
        cat $my_file $my_file > ${my_file.simpleName}.duplicated.txt
        """
}
```

And modify your workflow block as follows

```groovy
workflow {
    say_hello()
    duplicate_lines( say_hello.out )
}
```

If you want to see how your `main.nf` should look like at this stage open this hidden section


<details>
<summary>Code</summary>
```groovy
nextflow.enable.dsl = 2

// this is a comment
process say_hello {
    // comments can be written anywhere
    output:
        path "hello_world.txt"
    script:
        """
        echo "This is the EBI predoc course" > hello_world.txt
        """
}

process duplicate_lines {
    publishDir "../nextflow_output/duplicate_lines"

    input:
        path my_file
    output:
        path "${my_file.simpleName}.duplicated.txt"
    script:
        """
        cat $my_file $my_file > ${my_file.simpleName}.duplicated.txt
        """
}

workflow {
    say_hello()
    duplicate_lines( say_hello.out )
}
```
</details>

Now run again the workflow with `nextflow run main.nf`.
This time your workflow will not print anything since we omitted the `view()` operator.
However, if you type in your terminal the following

```bash
cat ../nextflow_output/duplicate_lines/hello_world.duplicated.txt
```

You should see the following

```
This is the EBI predoc course
This is the EBI predoc course
```

So as you see, the content of the `hello_world.txt` file that we created before has been duplicated so that it appears twice and it has been placed on a new file, `../nextflow_output/duplicate_lines/hello_world.duplicated.txt`.

Let's analyse what happened this time:

- We created another process called `duplicate_lines` which duplicates a given file thanks to its `script` command `cat $my_file $my_file > ${my_file.simpleName}.duplicated.txt`
- `duplicate_lines` declares an `input:` block. The input block is similar to the output block that we saw before in that it can use the `path` qualifier to declare the input to be a file. However, what comes after `path` does not need to be a real filename, it is just a variable name (note that it is not quoted). Nextflow replaces that variable with the real name of the file given in input.
- In the script and output blocks we can refer to the inputs by specifying `$my_file`. Note that we need to use the same name used in the input declaration.
  - It is possible to enclose the variable name in curly braces to demark it from other text. So `${my_file}` is equivalent to `$my_file`.
  - We applied the operator `simpleName` to the variable `$my_file` by writing `${my_file.simpleName}`. This removes the path and the extension from `my_file`, so that we can use it to name our output file (if `$my_file` contains the value `"/some/path/hello_world.txt"`, then `${my_file.simpleName}` contains only `hello_world`).
- We used a new directive in the process `duplicate_lines`, called `publishDir`. This specifies the folder where the output of the process should be placed at the end of the execution. This is usually done to put the final outputs of your workflow in a meaningful directory structure. In our case, `publishDir "../nextflow_output/duplicate_lines"` places `${my_file.simpleName}.duplicated.txt` in the folder `../nextflow_output/duplicate_lines`
- In the workflow block we called the process `duplicate_lines` with `say_hello.out` as an argument. So the output of `say_hello` is used as an input for `duplicate_lines`. Note that the number of arguments provided to a process must match the number of arguments declared in its input block.

## Creating channels and specifying pipeline parameters

The workflow that we wrote works as expected but it is not very useful since we cannot specify dynamically its input files. We will now learn how to use pipeline parameters to specify an external input file for the whole workflow and how to use channel factories to feed it to our processes.

First create a text file called `../nextflow_inputs/a_file.txt` containing the string `"This is the file content"`

```bash
mkdir ../nextflow_inputs
echo "This is the file content" > ../nextflow_inputs/a_file.txt
```

Modify the workflow as follows

```groovy
workflow {
    Channel.fromPath( params.input_file ).set{ input_ch }
    duplicate_lines( input_ch )
}
```

If you want to see how your `main.nf` should look like at this stage open this hidden section

<details>
<summary>Code</summary>
```groovy
nextflow.enable.dsl = 2

// this is a comment
process say_hello {
    // comments can be written anywhere
    output:
        path "hello_world.txt"
    script:
        """
        echo "This is the EBI predoc course" > hello_world.txt
        """
}

process duplicate_lines {
    publishDir "../nextflow_output/duplicate_lines"

    input:
        path my_file
    output:
        path "${my_file.simpleName}.duplicated.txt"
    script:
        """
        cat $my_file $my_file > ${my_file.simpleName}.duplicated.txt
        """
}

workflow {
    Channel.fromPath( params.input_file ).set{ input_ch }
    duplicate_lines( input_ch )
}
```
</details>

Now open the file `nextflow.config` and add the following

```groovy
params {
  input_file = "../nextflow_inputs/a_file.txt"
}
```

If you want to see how your `nextflow.config` should look like at this stage open this hidden section

<details>
<summary>Code</summary>
```groovy
// you can also put comments in nextflow.config
workDir = "../nextflow_workdir"

params {
  input_file = "../nextflow_inputs/a_file.txt"
}
```
</details>

Now run again the workflow with `nextflow run main.nf`.
This time if you examine the folder `../nextflow_output/duplicate_lines` you will find a file called `a_file.duplicated.txt`. Let's see it's content.

```bash
cat ../nextflow_output/duplicate_lines/a_file.duplicated.txt
```

This should print

```
This is the file content
This is the file content
```

So the content of the file that we created before, `a_file.txt` was duplicated and placed in the file `a_file.duplicated.txt` in the folder `../nextflow_output/duplicate_lines`.
Let's examine what happened:

- In `nextflow.config`, we declared a `params` block. Any variable written inside this block, like `input_file = "../nextflow_inputs/a_file.txt"`, is accessible in the workflow by writing `params.<variable_name>`, so `params.input_file` in this case.
- In `main.nf`, we wrote `Channel.fromPath( params.input_file )`. This uses the channel factory `Channel.fromPath` to create a new channel using the content of `params.input_file`. The `Channel.fromPath` factory interprets its argument to be the path to a file.
- After `Channel.fromPath( params.input_file )` we added `set{ input_ch }` (note the curly braces: it is a [closure](https://www.wikiwand.com/en/Closure_(computer_programming)), we will explore later what does it mean). This assigns to the newly created channel the name `input_ch`
- We then used the channel `input_ch` as an input for the process `duplicate_lines` in the statement `duplicate_lines( input_ch )`. Since the channel `input_ch` contains the variable `params.input_file`, which we declared to contain the value `../nextflow_inputs/a_file.txt`, this file is given in input to `duplicate_lines`
- `duplicate_lines` performed its function as before, putting its output in `../nextflow_output/duplicate_lines`

Instead than hard-coding parameters in `nextflow.config`, it is also possible to pass them on the command line. So for example we could have omitted the `params` block in `nextflow.config` and run

```bash
nextflow run main.nf --input_file ../nextflow_inputs/a_file.txt
```

This produces the same result. Note that pipeline parameters need to be specified with two prepending dashes (`--my_parameter`).
This differentiates them from command line options for Nextflow itself, such as `-dry-run`, which use a single dash.

## Multiple input files

We are now able to process a single file with our pipeline, but what if we have many files that we need to process in the same way?
One approach for this is to use a [glob pattern](https://www.wikiwand.com/en/Glob_(programming)) as an input.

Let's create a bunch of files to use in input

```bash
echo "This is content of file 1" > ../nextflow_inputs/set_of_files_1.txt
echo "This is content of file 2" > ../nextflow_inputs/set_of_files_2.txt
echo "This is content of file 3" > ../nextflow_inputs/set_of_files_3.txt
echo "This is content of file 4" > ../nextflow_inputs/set_of_files_4.txt
echo "This is content of file 5" > ../nextflow_inputs/set_of_files_5.txt
echo "This is content of file 6" > ../nextflow_inputs/set_of_files_6.txt
echo "This is content of file 7" > ../nextflow_inputs/set_of_files_7.txt
echo "This is content of file 8" > ../nextflow_inputs/set_of_files_8.txt
```

Now we just need to modify `input_file` in `nextflow.config`

```groovy
params {
  input_file = "../nextflow_inputs/set_of_files_*.txt"
}
```

If you want to see how your `nextflow.config` should look like at this stage open this hidden section

<details>
<summary>Code</summary>
```groovy
// you can also put comments in nextflow.config
workDir = "../nextflow_workdir"

params {
  input_file = "../nextflow_inputs/set_of_files_*.txt"
}
```
</details>

Now run again the workflow with `nextflow run main.nf`.
This time if you examine the output folder with `ls ../nextflow_output/duplicate_lines` you will find a set of files

```
a_file.duplicated.txt
set_of_files_1.duplicated.txt
set_of_files_2.duplicated.txt
set_of_files_3.duplicated.txt
set_of_files_4.duplicated.txt
set_of_files_5.duplicated.txt
set_of_files_6.duplicated.txt
set_of_files_7.duplicated.txt
set_of_files_8.duplicated.txt
```

Like before, each of them will contain the duplicated version of the original files.

Let's examine what happened:

- We changed `params.input_ch` to contain a glob pattern. This is expanded by Nextflow to yield a list of matching files.
- The matching files are fed one by one via the channel `input_ch` to the process `duplicate_lines`
- `duplicate_lines` operates independently but in parallel on all the inputs, producing the output files. Each task is executed in its own private directory.

## Using a sample sheet and value channels

Using glob patterns for specifying samples is useful and quick, but what if we want to specify input files that live in many different directories with very different names?
And if we want some files to be processed in pairs with other specific files, or with specific parameters?
For such use cases a sample sheet is the easiest solution and it is the recommended way to specify workflow inputs.

A sample sheet is just a [csv](https://www.wikiwand.com/en/Comma-separated_values) file with one row per file to be processed, and with each column specifying either a file or a parameter.
Create a sample sheet called `../nextflow_inputs/samplesheet.csv` with the following content


```bash
sample,content
../nextflow_inputs/set_of_files_1.txt,"csv input 1"
../nextflow_inputs/set_of_files_2.txt,"csv input 2"
../nextflow_inputs/set_of_files_3.txt,"csv input 3"
../nextflow_inputs/set_of_files_4.txt,"csv input 4"
../nextflow_inputs/set_of_files_5.txt,"csv input 5"
../nextflow_inputs/set_of_files_6.txt,"csv input 6"
../nextflow_inputs/set_of_files_7.txt,"csv input 7"
../nextflow_inputs/set_of_files_8.txt,"csv input 8"
```

Now create a process called `append_to_file`

```groovy
process append_to_file {
    publishDir "../nextflow_output/write_text_file"

    input:
        path my_file
        val my_val
    output:
        path "${my_file.simpleName}.duplicated.txt"
    script:
        """
        cat $my_file > ${my_file.simpleName}.appended.txt
        echo "$my_val" >> ${my_file.simpleName}.appended.txt
        """
}
```

And modify the workflow as follows

```groovy
workflow {
    Channel.fromPath( params.samplesheet )
      .splitCsv( header: true )
      .set{ input_ch }

    input_ch.map{ it["sample"] }.set{ sample_ch }
    input_ch.map{ it["content"] }.set{ content_ch }

    duplicate_lines( sample_ch )
    append_to_file( duplicate_lines.out, content_ch )
}
```

If you want to see how your `main.nf` file should look like at this stage open this hidden section

<details>
<summary>Code</summary>
```groovy
nextflow.enable.dsl = 2

// this is a comment
process say_hello {
    // comments can be written anywhere
    output:
        path "hello_world.txt"
    script:
        """
        echo "This is the EBI predoc course" > hello_world.txt
        """
}

process duplicate_lines {
    publishDir "../nextflow_output/duplicate_lines"

    input:
        path my_file
    output:
        path "${my_file.simpleName}.duplicated.txt"
    script:
        """
        cat $my_file $my_file > ${my_file.simpleName}.duplicated.txt
        """
}

process append_to_file {
    publishDir "../nextflow_output/write_text_file"

    input:
        path my_file
        val my_val
    output:
        path "${my_file.simpleName}.duplicated.txt"
    script:
        """
        cat $my_file > ${my_file.simpleName}.appended.txt
        echo "$my_val" >> ${my_file.simpleName}.appended.txt
        """
}

workflow {
    Channel.fromPath( params.samplesheet )
      .splitCsv( header: true )
      .set{ input_ch }

    input_ch.map{ it["sample"] }.set{ sample_ch }
    input_ch.map{ it["content"] }.set{ content_ch }

    duplicate_lines( sample_ch )
    append_to_file( duplicate_lines.out, content_ch )
}
```
</details>

Now we need to add the parameter `samplesheet` in `nextflow.config`

```groovy
params {
  input_file = "../nextflow_inputs/set_of_files_*.txt"
  samplesheet = "../nextflow_inputs/samplesheet.csv"
}
```

If you want to see how your `nextflow.config` should look like at this stage open this hidden section

<details>
<summary>Code</summary>
```groovy
// you can also put comments in nextflow.config
workDir = "../nextflow_workdir"

params {
  input_file = "../nextflow_inputs/set_of_files_*.txt"
  samplesheet = "../nextflow_inputs/samplesheet.csv"
}
```
</details>

Now run again the workflow with `nextflow run main.nf`.
This time if you examine the output folder with `ls ../nextflow_output/append_to_file` you will find a set of files

```
set_of_files_1.append_to_file.txt
set_of_files_2.append_to_file.txt
set_of_files_3.append_to_file.txt
set_of_files_4.append_to_file.txt
set_of_files_5.append_to_file.txt
set_of_files_6.append_to_file.txt
set_of_files_7.append_to_file.txt
set_of_files_8.append_to_file.txt
```

Taking as an example the first one, `set_of_files_1.append_to_file.txt` it should contain

```
This is content of file 1
This is content of file 1
csv input 1
```

While the second one, `set_of_files_2.append_to_file.txt`, should contain

```
This is content of file 2
This is content of file 2
csv input 2
```

Let's examine what happened:

- We created the process `append_to_file`, which takes in input a file (`path my_file`) and a value (`val my_val`). This process copies the content of `my_file` to `${my_file.simpleName}.append_to_file.txt` and then appends to the newly created file the content of `my_val`
- We defined the parameter `samplesheet` in `nextflow.config`
- We modified the workflow so that we use `params.samplesheet` to create a channel with `Channel.fromPath`
- We applied the operator `splitCsv` to this channel containing the samplesheet, using the option `header: true`. This operator reads the file contained in the channel assuming it to be a csv file with an header line. Then it produces in output another channel containing, for each row in the samplesheet, a groovy map (what in Python would be called a [dictionary](https://en.wikibooks.org/wiki/A-level_Computing/AQA/Paper_1/Fundamentals_of_data_structures/Dictionaries)). This map contains a key for each element in the csv header, and a value corresponding to the value of that column in the current line of the csv file.
- We apply the `map` operator (`.map{ it["sample"] }`) to the resulting channel
  - The map operator is follwed by a [closure](https://www.wikiwand.com/en/Closure_(computer_programming)) (`{ it["sample"] }`)
  - You can think of a closure as an unnamed function (like a lambda function in Python)
  - The `map` operator calls this unnamed function for each element in the channel, and creates another channel containing the respective function outputs
  - Closure understand the implicit variable `it`, which represents whatever imput is given to the function
  - If an explicit return statement is not present in the closure, the last evaluated expression is returned by the closure ( `it["sample"]` in this case)
- Since `splitCsv` created a dictionary for each item in the samplesheet, `map{ it["sample"] }` replaces that dictionary (`it` in the closure) with the content of the value contained in it under the key `"sample"`
- `input_ch` is used again in `input_ch.map{ it["content"] }.set{ content_ch }` to extract the value of `content` for each sample from the samplesheet
  - Channels can be used many times, and each time all the files contained in it are processed. So both `input_ch.map{ it["content"] }.set{ content_ch }` and `input_ch.map{ it["sample"] }.set{ sample_ch }` process every element in `input_ch`
- We created the channels `sample_ch` and `content_ch` using the `set` operator. They contain respectively the sample files and the `content` values related to them.
  - The order of processing in a channel is guaranteed, so we can be sure that each sample will be paired with the correct `content` value
- We fed `sample_ch` to `duplicate_lines`
- We fed the output of `duplicate_lines` to `append_to_file`, together with the values in `content_ch`
- `append_to_file` appended the value of `content_ch` to the output of `duplicate_lines`, creating the final result

Note that we introduced a new qualifier: `val`. The `val` qualifier specifies a value, differently from the `path` qualifier that specifies a file. If I write `val variable_name`, then `variable_name` can contain something like a string or a number, depending on what is fed to the process input.
It is also possible to manually create value channels using the channel factory `Channel.value`.
Take as an example the following

```groovy
workflow{
  Channel.value(1, 2, 3).view()
}
```

This would produce a channel containing in order the values 1, 2, and 3. These would then be printed one by one to the terminal by the view operator.

## Software dependencies and resource allocation

## The resume feature

## Using external scripts

## nf-core pipelines

## Additional notes

## Basic challenge
